# python-resource-notes
Record some tools or packages that I find useful and helpful for my development.

There are many related tools, but Iâ€™m only listing the ones I use most frequently or that I personally prefer â¤ï¸

If you want to learn more, I recommend checking out the following link:
https://github.com/vinta/awesome-python

## ðŸ”»Deep Learning
### â–¶ï¸Ž [Pytorch](https://github.com/pytorch/pytorch)
- å€‹äººèªç‚ºpytorchç›¸å°tensorflowæ›´å®¹æ˜“ä¸Šæ‰‹

### â–¶ï¸Ž [Lime](https://github.com/marcotcr/lime) (local interpretable model-agnostic explanations)
- Develop explainable, interpretable deep learning models.

## ðŸ”»Data Visualization
### â–¶ï¸Ž [Plotly](https://plotly.com/python)
### â–¶ï¸Ž [PyVis](https://towardsdatascience.com/pyvis-visualize-interactive-network-graphs-in-python-77e059791f01)
- Visualize interactive network graphs


## ðŸ”» OCR
### â–¶ï¸Ž [EasyOCR](https://github.com/JaidedAI/EasyOCR)
- æ”¯æŒä¸­æ–‡ã€æ•¸å­—è¾¨åˆ¥æ•ˆæžœå¥½(ç¶“é©—)
- ç°¡å–®ã€æ•ˆæžœå¥½
```
# pip install easyocr

import easyocr

reader = easyocr.Reader(['ch_tra', 'en'], gpu=True)
image_path = 'è·¯å¾‘'
result = reader.readtext(image_path)

for (bbox, text, prob) in result:
    print(bbox)
    print(text)
    print(prob)
```
### â–¶ï¸Ž [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
- ç´”è‹±æ–‡è¾¨è­˜èƒ½åŠ›ä½³(ç¶“é©—)ã€ä½†å»ºè­°ä½¿ç”¨EasyOCRå³å¯

## ðŸ”» NLP

### â–¶ï¸Ž [sentence-transformers](https://github.com/UKPLab/sentence-transformers)
- based on Bert, transformer model
- å¯ä»¥ç°¡å–®å¯¦è¸å­—ä¸²ç›¸ä¼¼åº¦æ¯”å°(similarity compare)
- [model list](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html)
```python=
# pip install -U sentence-transformers

# 1. Load a pretrained Sentence Transformer model
model = SentenceTransformer("model name")

# 2. Prepare sentences to encode
sentences = [
    "This is sentence 1 example.",
    "This is sentence 2 example.",
]

# 3. Make prompt if you need
your_prompt = ""

# 4.  Calculate embeddings by calling model.encode()
embeddings = model.encode(sentences, prompt=your_prompt)

# 5. Calculate the embedding similarities
model.similarity(query_embedding, passage_embeddings)
```



### â–¶ï¸Ž [Hugging Face transformers ](https://github.com/huggingface/transformers)
- You can instantiate ```AutoModelForCausalLM``` model and  ```AutoTokenizer``` 
- https://huggingface.co/docs/transformers/llm_tutorial
- Make transformers pipeline easy





## ðŸ”»LLM agent flow
### â–¶ï¸Ž [Flowise](https://github.com/FlowiseAI/Flowise)
### â–¶ï¸Ž [LangFlow](https://github.com/langflow-ai/langflow)

## ðŸ”»API
### â–¶ï¸Ž FastAPI
- è¢«èªç‚ºæ˜¯ç•¶å‰æœ€å¿«çš„ Python æ¡†æž¶ä¹‹ä¸€ï¼Œ[æ˜“ç”¨ä¸”ç°¡æ½”](https://medium.com/seaniap/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-%E7%B0%A1%E5%96%AE%E6%98%93%E6%87%82-python%E6%96%B0%E6%89%8B%E7%9A%84fastapi%E4%B9%8B%E6%97%85-ebd09dc0167b)
- æœƒè‡ªå‹•ç”Ÿæˆäº’å‹•å¼ API æ–‡æª”
- æä¾›äº†å¼·å¤§çš„é¡žåž‹æª¢æŸ¥åŠŸèƒ½ï¼Œå¯ä»¥èˆ‡å…¶ä»–å·¥å…·/å¥—ä»¶æ•´åˆ (å¾…è£œ)
```
# pip  install fastapi 
# pip install uvicorn # ASGIä¼ºæœå™¨

from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def read_root():
    return {"Hello": "FastAPI"}
```
- ä½¿ç”¨uvicornä¾†å•Ÿå‹•ä¼ºæœå™¨
```bash
# main æ˜¯æ‚¨Pythonæª”æ¡ˆåï¼Œappæ˜¯çš„FastAPIå¯¦ä¾‹

uvicorn main:app --reload
```

## ðŸ”» UI (for analysis)
### â–¶ï¸Ž [Gradio](https://github.com/gradio-app/gradio)

### â–¶ï¸Ž [Streamlit](https://github.com/streamlit/streamlit)


## ðŸ”» UI Dashboard
### â–¶ï¸Ž [Metabase](https://www.metabase.com/)

------------
## ðŸ”» Proxy (ä»£ç†å·¥å…·)
### â–¶ï¸Ž[mitmproxy](https://mitmproxy.org/)
- é–‹æºæŠ“åŒ…å·¥å…·
- æ”¯æŒåå‘ä»£ç†ï¼Œå°‡æµé‡è½‰ç™¼åˆ°æŒ‡å®šçš„æœå‹™å™¨
- å¯ä»¥èˆ‡pythoné€²è¡Œäº¤äº’ï¼Œå¯ä»¥ä½¿ç”¨Pythonç·¨å¯«è…³æœ¬ä¾†è‡ªå‹•åŒ–æµé‡è™•ç†
- è‡ªè¨‚HTTPéŸ¿æ‡‰
```
from mitmproxy import http

def request(flow: http.HTTPFlow) -> None:
    flow.response = http.Response.make(
        204,
        '{"foo":"bar"}',
        {"Content-Type": "application/json"}
    )
```


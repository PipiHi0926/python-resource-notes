# python-resource-notes
Record some tools or packages that I find useful and helpful for my development.





## ğŸ”»Deep Learning
### â–¶ï¸ [Lime](https://github.com/marcotcr/lime) (local interpretable model-agnostic explanations)
- Develop explainable, interpretable deep learning models.

## ğŸ”»Data Visualization
### â–¶ï¸ [Plotly](https://plotly.com/python)
### â–¶ï¸ [PyVis](https://towardsdatascience.com/pyvis-visualize-interactive-network-graphs-in-python-77e059791f01)
- Visualize interactive network graphs


## ğŸ”» NLP

### â–¶ï¸ [sentence-transformers](https://github.com/UKPLab/sentence-transformers)
- based on Bert, transformer model
- å¯ä»¥ç°¡å–®å¯¦è¸å­—ä¸²ç›¸ä¼¼åº¦æ¯”å°(similarity compare)
- [model list](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html)
```python=
# pip install -U sentence-transformers

# 1. Load a pretrained Sentence Transformer model
model = SentenceTransformer("model name")

# 2. Prepare sentences to encode
sentences = [
    "This is sentence 1 example.",
    "This is sentence 2 example.",
]

# 3. Make prompt if you need
your_prompt = ""

# 4.  Calculate embeddings by calling model.encode()
embeddings = model.encode(sentences, prompt=your_prompt)

# 5. Calculate the embedding similarities
model.similarity(query_embedding, passage_embeddings)
```



### â–¶ï¸ [Hugging Face transformers ](https://github.com/huggingface/transformers)
- You can instantiate ```AutoModelForCausalLM``` model and  ```AutoTokenizer``` 
- https://huggingface.co/docs/transformers/llm_tutorial
- Make transformers pipeline easy





## ğŸ”»LLM agent flow
### â–¶ï¸ [Flowise](https://github.com/FlowiseAI/Flowise)
### â–¶ï¸ [LangFlow](https://github.com/langflow-ai/langflow)


## ğŸ”» UI (for analysis)
### â–¶ï¸ [Gradio](https://github.com/gradio-app/gradio)

### â–¶ï¸ [Streamlit](https://github.com/streamlit/streamlit)


##  UI Dashboard
### â–¶ï¸ [Metabase](https://www.metabase.com/)

